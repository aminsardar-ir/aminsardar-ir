{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNZzSQPiIZ34xEr3lyvVy+2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminsardar-ir/aminsardar-ir/blob/main/MnistLoad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Training and Validation Data**\n",
        "\n",
        "The MNIST dataset is conveniently bundled within Keras, and we can easily analyze some of its features in Python.\n",
        "\n"
      ],
      "metadata": {
        "id": "TcINkkBaPbmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "# load (downloaded if needed) the MNIST dataset\n",
        "(X_train, y_train), (X_val, y_val) = mnist.load_data()"
      ],
      "metadata": {
        "id": "8hM2A_hGPo16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)"
      ],
      "metadata": {
        "id": "Ev_8d-Z6Rsc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing necessary Libraries**"
      ],
      "metadata": {
        "id": "05RGqdDkP3N0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential # Model type to be used\n",
        "from keras.layers import Dense, Activation# Make Fully connected (FC) layers\n",
        "from keras.utils import np_utils  # NumPy related tools\n",
        "\n",
        "import matplotlib.pyplot as plt      # MATLAB like plotting routines\n",
        "import random                        # for generating random numbers"
      ],
      "metadata": {
        "id": "AD84EukGP8lA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6N5h30Cq-4nW"
      },
      "source": [
        "Visualization of some input images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb6D4wpu-7AP"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (9,9) # Make the figures a bit bigger\n",
        "\n",
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    num = random.randint(0, len(X_train))\n",
        "    plt.imshow(X_train[num], cmap='gray', interpolation='none')\n",
        "    plt.title(\"Class {}\".format(y_train[num]))\n",
        "    \n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMORUbgX_Hce"
      },
      "source": [
        "Formatting the input data layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVhh053q_J5D"
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 784).astype('float32')\n",
        "X_val = X_val.reshape(X_val.shape[0], 784).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train /= 255\n",
        "X_val /= 255\n",
        "\n",
        "# one hot encode outputs\n",
        "Y_train = np_utils.to_categorical(y_train)\n",
        "Y_val = np_utils.to_categorical(y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hZkBAg1_l3W"
      },
      "source": [
        "Building the simplest fully connected network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gntew4mq_ncb"
      },
      "source": [
        "# The Sequential model is a linear stack of layers and is very common.\n",
        "model = Sequential([\n",
        "    Dense(10), # It is the output layer and should be equal to the number of desired classes (10 in this case).\n",
        "    Activation('softmax'),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "vHeki2VnRFQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZUKnXEVArMf"
      },
      "source": [
        "model.fit(X_train, Y_train, \n",
        "          validation_data=(X_val, Y_val),\n",
        "          epochs=5, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_val, Y_val)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "_BWkdskBS9gU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropout helps protect the model from memorizing or \"overfitting\" the training data.\n",
        "modelDeepFC = Sequential([\n",
        "    Dense(200, input_shape=(784,)),\n",
        "    Activation('relu'),\n",
        "    Dense(100, input_shape=(200,)),\n",
        "    Activation('relu'),\n",
        "    Dense(60, input_shape=(100,)),\n",
        "    Activation('relu'),\n",
        "    Dense(30, input_shape=(60,)),\n",
        "    Activation('relu'),\n",
        "    Dense(10),\n",
        "    Activation('softmax'),\n",
        "])"
      ],
      "metadata": {
        "id": "zLS4ZQoaTT7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelDeepFC.compile(loss='categorical_crossentropy', \n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "modelDeepFC.fit(X_train, Y_train, \n",
        "          validation_data=(X_val, Y_val),\n",
        "          epochs=5, batch_size=32)"
      ],
      "metadata": {
        "id": "JOECVcCXTcQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten"
      ],
      "metadata": {
        "id": "KP3nNhbqT-w7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload the MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "npzwLScaV7ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Again, do some formatting\n",
        "# Except we do not flatten each image into a 784-length vector because we want to perform convolutions first\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') #add an additional dimension to represent the single-channel\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "X_train /= 255                              # normalize each value for each pixel for the entire vector for each input\n",
        "X_test /= 255\n",
        "\n",
        "# one hot encode outputs\n",
        "Y_train = np_utils.to_categorical(y_train)\n",
        "Y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "print(\"Training matrix shape\", X_train.shape)\n",
        "print(\"Testing matrix shape\", X_test.shape)"
      ],
      "metadata": {
        "id": "y_BZZHZJUPaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelCNN = Sequential([\n",
        "    \n",
        "    # Convolution Layer 1\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)), # 32 different 3x3 kernels -- so 32 feature maps\n",
        "    MaxPooling2D(pool_size=(2, 2)), # Pool the max values over a 2x2 kernel\n",
        "\n",
        "    # Convolution Layer 2\n",
        "    Conv2D(64, (3, 3), activation='relu'), # 64 different 3x3 kernels \n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    # Convolution Layer 3\n",
        "    Conv2D(128, (3, 3), activation='relu'), # 128 different 3x3 kernels\n",
        "\n",
        "    Flatten(), # Flatten final 7x7x128 output matrix into a 1024-length vector \n",
        "\n",
        "    # Fully Connected Layer 4\n",
        "    Dense(512), # 512 FCN nodes\n",
        "    Activation('relu'),\n",
        "    Dense(10),\n",
        "    Activation('softmax'),\n",
        "])\n",
        "modelCNN.summary()"
      ],
      "metadata": {
        "id": "svmjfksBUZQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelCNN.compile(loss='categorical_crossentropy', \n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "modelCNN.fit(X_train, Y_train, \n",
        "          validation_data=(X_test, Y_test),\n",
        "          epochs=5, batch_size=32)"
      ],
      "metadata": {
        "id": "My5oW4QcUgBD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}